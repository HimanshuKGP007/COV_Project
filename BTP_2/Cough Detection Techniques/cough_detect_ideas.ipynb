{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import torch\n",
    "import numpy as np\n",
    "from net import Net\n",
    "import pickle\n",
    "\n",
    "data_dir = '../data'\n",
    "folders = os.listdir(data_dir)\n",
    "\n",
    "# data to be extracted\n",
    "\n",
    "X = np.empty((0,1024))\n",
    "labels = []\n",
    "\n",
    "# initialize net\n",
    "\n",
    "param_path = 'mx-h64-1024_0d3-1.17.pkl'\n",
    "net = Net(param_path)\n",
    "net.eval()\n",
    "\n",
    "for label,folder in enumerate(folders): # classes\n",
    "    for file in os.listdir(os.path.join(data_dir,folder)):\n",
    "        \n",
    "        # load the WAV file\n",
    "        \n",
    "        y,sr = librosa.load(path = os.path.join(data_dir,folder,file),\n",
    "                            sr = None)\n",
    "        \n",
    "        # convert to mono if necessary\n",
    "        \n",
    "        if y.ndim > 1:\n",
    "            y = librosa.to_mono(y = y)\n",
    "            \n",
    "        # resample to 44.1 kHz if necessary\n",
    "        \n",
    "        target_sr = 44100\n",
    "        \n",
    "        if sr != target_sr:\n",
    "            y = librosa.resample(y = y,\n",
    "                                 orig_sr = sr,\n",
    "                                 target_sr = target_sr)\n",
    "        \n",
    "        # compute the Mel-scale spectrogram\n",
    "        \n",
    "        mel_specgram = librosa.feature.melspectrogram(y = y,\n",
    "                                                      sr = target_sr,\n",
    "                                                      n_fft = 1024,\n",
    "                                                      hop_length = 512,\n",
    "                                                      n_mels = 128)\n",
    "        \n",
    "        # apply log transformation to dilate values\n",
    "        \n",
    "        log_mel_specgram = librosa.power_to_db(mel_specgram)\n",
    "        \n",
    "        # this is necessary because PyTorch throws an error if one of the\n",
    "        # image dimensions is less than 128. This is because a 128 x 128\n",
    "        # image is too small for the net architecture\n",
    "        \n",
    "        if log_mel_specgram.shape[0] < 128:\n",
    "            pad_width = ((0,128 - log_mel_specgram.shape[0]),(0,0))\n",
    "            log_mel_specgram = np.pad(log_mel_specgram,pad_width)\n",
    "        elif log_mel_specgram.shape[1] < 128:\n",
    "            pad_width = ((0,0),(0,128 - log_mel_specgram.shape[1]))\n",
    "            log_mel_specgram = np.pad(log_mel_specgram,pad_width)\n",
    "        \n",
    "        # Add batch and channel dimensions because input to net needs to be\n",
    "        # 4D (N x C x H x W)\n",
    "        \n",
    "        target_shape = (1,1,log_mel_specgram.shape[0],log_mel_specgram.shape[1])\n",
    "        log_mel_specgram = np.reshape(log_mel_specgram,target_shape)\n",
    "        \n",
    "        # convert to torch tensor\n",
    "        \n",
    "        log_mel_specgram = torch.from_numpy(log_mel_specgram)\n",
    "        \n",
    "        # extract feature vector\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            fv = net(log_mel_specgram).numpy()\n",
    "        \n",
    "        # append to dataset\n",
    "        \n",
    "        X = np.vstack((X,fv))\n",
    "        labels.append(label)    \n",
    "\n",
    "# save the feature vectors and their labels\n",
    "\n",
    "with open('../features/X.npy','wb') as f:\n",
    "    np.save(file = f, arr = X)\n",
    "\n",
    "with open('../features/labels.pkl','wb') as f:\n",
    "    pickle.dump(labels,f)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
