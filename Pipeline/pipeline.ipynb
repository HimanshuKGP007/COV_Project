{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "import pandas as pd #To hand with data \r\n",
    "import numpy as np #To math \r\n",
    "import seaborn as sns #to visualization\r\n",
    "import matplotlib.pyplot as plt # to plot the graphs\r\n",
    "import matplotlib.gridspec as gridspec # to do the grid of plots\r\n",
    "\r\n",
    "from sklearn.metrics import classification_report\r\n",
    "from sklearn.datasets import load_breast_cancer\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "from sklearn import metrics\r\n",
    "from sklearn.metrics import confusion_matrix\r\n",
    "from sklearn.metrics import classification_report\r\n",
    "from sklearn.model_selection import cross_val_score\r\n",
    "from sklearn.model_selection import RepeatedKFold\r\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\r\n",
    "\r\n",
    "#models\r\n",
    "from interpret.glassbox import ExplainableBoostingClassifier\r\n",
    "from sklearn.linear_model import LogisticRegression\r\n",
    "from sklearn.ensemble import RandomForestClassifier\r\n",
    "from sklearn.tree import DecisionTreeClassifier\r\n",
    "from xgboost import XGBClassifier\r\n",
    "from sklearn.ensemble import StackingClassifier"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "# Source CSV\r\n",
    "#df = pd.read_csv(r\"../input/coughclassifier-trial/Smote_data.csv\")\r\n",
    "df = pd.read_csv(r\"C:\\Users\\DELL\\COV_Project\\Pipeline\\with_coswara_csv_smote.csv\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "# 1 - Healthy\r\n",
    "# 0 - COVID +ve\r\n",
    "seed = 1"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "X = df.iloc[: ,:-1]\r\n",
    "Y = df.iloc[: ,-1]\r\n",
    "\r\n",
    "#Split\r\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state=42)\r\n",
    "\r\n",
    "features = ['chroma_stft', 'rmse', 'spectral_centroid', 'spectral_bandwidth',\r\n",
    "       'rolloff', 'zero_crossing_rate', 'mfcc1', 'mfcc2', 'mfcc3', 'mfcc4',\r\n",
    "       'mfcc5', 'mfcc6', 'mfcc7', 'mfcc8', 'mfcc9', 'mfcc10', 'mfcc11',\r\n",
    "       'mfcc12', 'mfcc13', 'mfcc14', 'mfcc15', 'mfcc16', 'mfcc17', 'mfcc18',\r\n",
    "       'mfcc19', 'mfcc20']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "# For testing various models\r\n",
    "# -----------------------------------------------------------------------------\r\n",
    "# # get a list of models to evaluate\r\n",
    "# def get_models():\r\n",
    "# \tmodels = dict()\r\n",
    "# \tmodels['rfc'] = RandomForestClassifier(random_state=1234)\r\n",
    "# \tmodels['logreg'] =  LogisticRegression()\r\n",
    "# \tmodels['clf'] = DecisionTreeClassifier(criterion=\"entropy\", max_depth=5)\r\n",
    "# \tmodels['XG Boost'] = XGBClassifier()\r\n",
    "# \tmodels['ebm'] = ExplainableBoostingClassifier(random_state=seed)\r\n",
    "# \tmodels['stacking'] = get_stacking()\r\n",
    "# \treturn models\r\n",
    " \r\n",
    "# # evaluate a given model using cross-validation\r\n",
    "# def evaluate_model(model, X, y):\r\n",
    "# \tcv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\r\n",
    "# \tscores = cross_val_score(model, X, y, scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1, error_score='raise')\r\n",
    "# \treturn scores\r\n",
    "\r\n",
    "# def evaluate_model1(model, X, y):\r\n",
    "# \tcv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\r\n",
    "# \tscores1 = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\r\n",
    "# \treturn scores1\r\n",
    "\r\n",
    "# # get the models to evaluate\r\n",
    "# models = get_models()\r\n",
    "# # evaluate the models and store results\r\n",
    "# results, names = list(), list()\r\n",
    "# for name, model in models.items():\r\n",
    "# \tscores = evaluate_model(model, X, Y)\r\n",
    "# \tscores1 = evaluate_model1(model, X, Y)\r\n",
    "# \tresults.append(scores)\r\n",
    "# \tnames.append(name)\r\n",
    "# \tprint('%s: %f, %f, %f' % (name, mean(scores1), mean(scores), std(scores)))\r\n",
    "# \tprint(scores)\r\n",
    "# \tprint(scores1)\r\n",
    "# \tprint(\"-----------------------------------------\")\r\n",
    "# # plot model performance for comparison\r\n",
    "# pyplot.boxplot(results, labels=names, showmeans=True)\r\n",
    "# pyplot.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Ensemble Model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "# make a prediction with a stacking ensemble\r\n",
    "# define the base models\r\n",
    "level0 = list()\r\n",
    "level0.append(('rfc', RandomForestClassifier(random_state=1234)))\r\n",
    "level0.append(('logreg', LogisticRegression()))\r\n",
    "level0.append(('XG Boost', XGBClassifier()))\r\n",
    "level0.append(('ebm', ExplainableBoostingClassifier(random_state=seed)))\r\n",
    "level0.append(('clf',DecisionTreeClassifier(criterion=\"entropy\", max_depth=5)))\r\n",
    "# define meta learner model\r\n",
    "level1 = LogisticRegression()\r\n",
    "# define the stacking ensemble\r\n",
    "model = StackingClassifier(estimators=level0, final_estimator=level1, cv=5)\r\n",
    "# fit the model on all available data\r\n",
    "model.fit(X_train, y_train)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[20:24:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[20:24:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:24:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:24:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:24:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:24:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "StackingClassifier(cv=5,\n",
       "                   estimators=[('rfc',\n",
       "                                RandomForestClassifier(random_state=1234)),\n",
       "                               ('logreg', LogisticRegression()),\n",
       "                               ('XG Boost',\n",
       "                                XGBClassifier(base_score=None, booster=None,\n",
       "                                              colsample_bylevel=None,\n",
       "                                              colsample_bynode=None,\n",
       "                                              colsample_bytree=None, gamma=None,\n",
       "                                              gpu_id=None,\n",
       "                                              importance_type='gain',\n",
       "                                              interaction_constraints=None,\n",
       "                                              learning_rate=None,\n",
       "                                              max_delta_step=No...\n",
       "                                              n_estimators=100, n_jobs=None,\n",
       "                                              num_parallel_tree=None,\n",
       "                                              random_state=None, reg_alpha=None,\n",
       "                                              reg_lambda=None,\n",
       "                                              scale_pos_weight=None,\n",
       "                                              subsample=None, tree_method=None,\n",
       "                                              validate_parameters=None,\n",
       "                                              verbosity=None)),\n",
       "                               ('ebm',\n",
       "                                ExplainableBoostingClassifier(random_state=1)),\n",
       "                               ('clf',\n",
       "                                DecisionTreeClassifier(criterion='entropy',\n",
       "                                                       max_depth=5))],\n",
       "                   final_estimator=LogisticRegression())"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "#model.score(X_test,y_test)\r\n",
    "predictions = model.predict(X_test)\r\n",
    "print(accuracy_score(y_test, predictions))\r\n",
    "print(confusion_matrix(y_test, predictions))\r\n",
    "print(classification_report(y_test, predictions))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.9638418079096045\n",
      "[[438  15]\n",
      " [ 17 415]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.96       453\n",
      "           1       0.97      0.96      0.96       432\n",
      "\n",
      "    accuracy                           0.96       885\n",
      "   macro avg       0.96      0.96      0.96       885\n",
      "weighted avg       0.96      0.96      0.96       885\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Save to Pickle File"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "import pickle\r\n",
    "filename = 'ensemble_model.sav'\r\n",
    "pickle.dump(model, open(filename, 'wb'))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Model Evaluation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "# # Evaluate predictions\r\n",
    "# print(accuracy_score(y_test, predictions))\r\n",
    "# print(confusion_matrix(y_test, predictions))\r\n",
    "# print(classification_report(y_test, predictions))\r\n",
    "\r\n",
    "# # Importing the metrics package from sklearn library\r\n",
    "# from sklearn import metrics\r\n",
    "# # Creating the confusion matrix\r\n",
    "# cm = metrics.confusion_matrix(y_test, y_pred)\r\n",
    "# # Assigning columns names\r\n",
    "# cm_df = pd.DataFrame(cm, \r\n",
    "#             columns = ['Predicted COVID+ve', 'Predicted Healthy'],\r\n",
    "#             index = ['Actual COVID+ve', 'Actual Healthy'])\r\n",
    "# # Showing the confusion matrix\r\n",
    "# cm_df\r\n",
    "\r\n",
    "# # Making the Confusion Matrix\r\n",
    "# from sklearn.metrics import confusion_matrix\r\n",
    "# from sklearn.metrics import classification_report\r\n",
    "# clf_rpt = classification_report(y_test,y_pred)\r\n",
    "# print(\"Accuracy =\", accuracy_score(y_test, y_pred))\r\n",
    "# print(clf_rpt)\r\n",
    "# cm = confusion_matrix(y_test, y_pred)\r\n",
    "# sns.heatmap(cm,annot=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "# import eli5\r\n",
    "# # create our dataframe of feature importances\r\n",
    "# feat_imp_df = eli5.explain_weights_df(rfc, feature_names=features)\r\n",
    "# feat_imp_df"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 13470.126256,
   "end_time": "2021-06-24T10:10:43.907785",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-06-24T06:26:13.781529",
   "version": "2.3.3"
  },
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}