{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "import pandas as pd #To hand with data \r\n",
    "import numpy as np #To math \r\n",
    "import seaborn as sns #to visualization\r\n",
    "import matplotlib.pyplot as plt # to plot the graphs\r\n",
    "import matplotlib.gridspec as gridspec # to do the grid of plots\r\n",
    "\r\n",
    "from sklearn.metrics import classification_report\r\n",
    "from sklearn.datasets import load_breast_cancer\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "from sklearn import metrics\r\n",
    "from sklearn.metrics import confusion_matrix\r\n",
    "from sklearn.metrics import classification_report\r\n",
    "from sklearn.model_selection import cross_val_score\r\n",
    "from sklearn.model_selection import RepeatedKFold\r\n",
    "from sklearn.metrics import precision_score, recall_score, fbeta_score, confusion_matrix, precision_recall_curve, accuracy_score\r\n",
    "from sklearn.preprocessing import MinMaxScaler\r\n",
    "from pathlib import Path\r\n",
    "import librosa\r\n",
    "from sklearn.pipeline import Pipeline\r\n",
    "\r\n",
    "#SMOTE\r\n",
    "from imblearn.pipeline import make_pipeline # To do our transformation in a unique time\r\n",
    "from imblearn.over_sampling import SMOTE\r\n",
    "from imblearn.metrics import classification_report_imbalanced\r\n",
    "\r\n",
    "#models\r\n",
    "from interpret.glassbox import ExplainableBoostingClassifier\r\n",
    "from sklearn.linear_model import LogisticRegression\r\n",
    "from sklearn.ensemble import RandomForestClassifier\r\n",
    "from sklearn.tree import DecisionTreeClassifier\r\n",
    "from xgboost import XGBClassifier\r\n",
    "from sklearn.ensemble import StackingClassifier"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "# Source CSV\r\n",
    "#df = pd.read_csv(r\"../input/coughclassifier-trial/Smote_data.csv\")\r\n",
    "df = pd.read_csv(r\"C:\\Users\\DELL\\COV_Project\\Pipeline\\with_coswara_csv_smote.csv\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "# 1 - Healthy\r\n",
    "# 0 - COVID +ve\r\n",
    "seed = 1"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "X = df.iloc[: ,:-1]\r\n",
    "Y = df.iloc[: ,-1]\r\n",
    "\r\n",
    "#Split\r\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state=42)\r\n",
    "\r\n",
    "features = ['chroma_stft', 'rmse', 'spectral_centroid', 'spectral_bandwidth',\r\n",
    "       'rolloff', 'zero_crossing_rate', 'mfcc1', 'mfcc2', 'mfcc3', 'mfcc4',\r\n",
    "       'mfcc5', 'mfcc6', 'mfcc7', 'mfcc8', 'mfcc9', 'mfcc10', 'mfcc11',\r\n",
    "       'mfcc12', 'mfcc13', 'mfcc14', 'mfcc15', 'mfcc16', 'mfcc17', 'mfcc18',\r\n",
    "       'mfcc19', 'mfcc20']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "# For testing various models\r\n",
    "# -----------------------------------------------------------------------------\r\n",
    "# # get a list of models to evaluate\r\n",
    "# def get_models():\r\n",
    "# \tmodels = dict()\r\n",
    "# \tmodels['rfc'] = RandomForestClassifier(random_state=1234)\r\n",
    "# \tmodels['logreg'] =  LogisticRegression()\r\n",
    "# \tmodels['clf'] = DecisionTreeClassifier(criterion=\"entropy\", max_depth=5)\r\n",
    "# \tmodels['XG Boost'] = XGBClassifier()\r\n",
    "# \tmodels['ebm'] = ExplainableBoostingClassifier(random_state=seed)\r\n",
    "# \tmodels['stacking'] = get_stacking()\r\n",
    "# \treturn models\r\n",
    " \r\n",
    "# # evaluate a given model using cross-validation\r\n",
    "# def evaluate_model(model, X, y):\r\n",
    "# \tcv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\r\n",
    "# \tscores = cross_val_score(model, X, y, scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1, error_score='raise')\r\n",
    "# \treturn scores\r\n",
    "\r\n",
    "# def evaluate_model1(model, X, y):\r\n",
    "# \tcv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\r\n",
    "# \tscores1 = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\r\n",
    "# \treturn scores1\r\n",
    "\r\n",
    "# # get the models to evaluate\r\n",
    "# models = get_models()\r\n",
    "# # evaluate the models and store results\r\n",
    "# results, names = list(), list()\r\n",
    "# for name, model in models.items():\r\n",
    "# \tscores = evaluate_model(model, X, Y)\r\n",
    "# \tscores1 = evaluate_model1(model, X, Y)\r\n",
    "# \tresults.append(scores)\r\n",
    "# \tnames.append(name)\r\n",
    "# \tprint('%s: %f, %f, %f' % (name, mean(scores1), mean(scores), std(scores)))\r\n",
    "# \tprint(scores)\r\n",
    "# \tprint(scores1)\r\n",
    "# \tprint(\"-----------------------------------------\")\r\n",
    "# # plot model performance for comparison\r\n",
    "# pyplot.boxplot(results, labels=names, showmeans=True)\r\n",
    "# pyplot.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Ensemble Model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "# make a prediction with a stacking ensemble\r\n",
    "# define the base models\r\n",
    "level0 = list()\r\n",
    "level0.append(('rfc', RandomForestClassifier(random_state=1234)))\r\n",
    "level0.append(('logreg', LogisticRegression()))\r\n",
    "level0.append(('XG Boost', XGBClassifier()))\r\n",
    "level0.append(('ebm', ExplainableBoostingClassifier(random_state=seed)))\r\n",
    "level0.append(('clf',DecisionTreeClassifier(criterion=\"entropy\", max_depth=5)))\r\n",
    "# define meta learner model\r\n",
    "level1 = LogisticRegression()\r\n",
    "# define the stacking ensemble\r\n",
    "model = StackingClassifier(estimators=level0, final_estimator=level1, cv=5)\r\n",
    "# fit the model on all available data\r\n",
    "model.fit(X_train, y_train)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[22:56:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[22:56:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[22:56:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[22:56:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[22:56:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[22:56:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "StackingClassifier(cv=5,\n",
       "                   estimators=[('rfc',\n",
       "                                RandomForestClassifier(random_state=1234)),\n",
       "                               ('logreg', LogisticRegression()),\n",
       "                               ('XG Boost',\n",
       "                                XGBClassifier(base_score=None, booster=None,\n",
       "                                              colsample_bylevel=None,\n",
       "                                              colsample_bynode=None,\n",
       "                                              colsample_bytree=None, gamma=None,\n",
       "                                              gpu_id=None,\n",
       "                                              importance_type='gain',\n",
       "                                              interaction_constraints=None,\n",
       "                                              learning_rate=None,\n",
       "                                              max_delta_step=No...\n",
       "                                              n_estimators=100, n_jobs=None,\n",
       "                                              num_parallel_tree=None,\n",
       "                                              random_state=None, reg_alpha=None,\n",
       "                                              reg_lambda=None,\n",
       "                                              scale_pos_weight=None,\n",
       "                                              subsample=None, tree_method=None,\n",
       "                                              validate_parameters=None,\n",
       "                                              verbosity=None)),\n",
       "                               ('ebm',\n",
       "                                ExplainableBoostingClassifier(random_state=1)),\n",
       "                               ('clf',\n",
       "                                DecisionTreeClassifier(criterion='entropy',\n",
       "                                                       max_depth=5))],\n",
       "                   final_estimator=LogisticRegression())"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "from sklearn.linear_model import LogisticRegression\r\n",
    "from sklearn.preprocessing import StandardScaler\r\n",
    "from sklearn.datasets import make_classification\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "from sklearn.pipeline import Pipeline\r\n",
    "X, y = make_classification(random_state=0)\r\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\r\n",
    "                                                    random_state=0)\r\n",
    "pipe = Pipeline([('scaler', StandardScaler()), ('lr', LogisticRegression())])\r\n",
    "# The pipeline can be used as any other estimator\r\n",
    "# and avoids leaking the test set into the train set\r\n",
    "pipe.fit(X_train, y_train)\r\n",
    "\r\n",
    "pipe.score(X_test, y_test)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.92"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "import sklearn; sklearn.show_versions()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "System:\n",
      "    python: 3.8.8 (default, Apr 13 2021, 15:08:03) [MSC v.1916 64 bit (AMD64)]\n",
      "executable: C:\\ProgramData\\Anaconda3\\python.exe\n",
      "   machine: Windows-10-10.0.19041-SP0\n",
      "\n",
      "Python dependencies:\n",
      "          pip: 21.1.2\n",
      "   setuptools: 52.0.0.post20210125\n",
      "      sklearn: 0.24.2\n",
      "        numpy: 1.19.5\n",
      "        scipy: 1.5.4\n",
      "       Cython: 0.29.21\n",
      "       pandas: 1.1.4\n",
      "   matplotlib: 3.4.2\n",
      "       joblib: 1.0.1\n",
      "threadpoolctl: 2.1.0\n",
      "\n",
      "Built with OpenMP: True\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "X_test.head()"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'head'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-c8ff277ea5c9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'head'"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "\r\n",
    "model.score(X_test,y_test)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.9638418079096045"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "#model.score(X_test,y_test)\r\n",
    "predictions = model.predict(X_test)\r\n",
    "print(accuracy_score(y_test, predictions))\r\n",
    "print(confusion_matrix(y_test, predictions))\r\n",
    "print(classification_report(y_test, predictions))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.9638418079096045\n",
      "[[438  15]\n",
      " [ 17 415]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.96       453\n",
      "           1       0.97      0.96      0.96       432\n",
      "\n",
      "    accuracy                           0.96       885\n",
      "   macro avg       0.96      0.96      0.96       885\n",
      "weighted avg       0.96      0.96      0.96       885\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Save to Pickle File"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "import pickle\r\n",
    "filename = 'ensemble_model.sav'\r\n",
    "pickle.dump(model, open(filename, 'wb'))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Model Evaluation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "# # Evaluate predictions\r\n",
    "# print(accuracy_score(y_test, predictions))\r\n",
    "# print(confusion_matrix(y_test, predictions))\r\n",
    "# print(classification_report(y_test, predictions))\r\n",
    "\r\n",
    "# # Importing the metrics package from sklearn library\r\n",
    "# from sklearn import metrics\r\n",
    "# # Creating the confusion matrix\r\n",
    "# cm = metrics.confusion_matrix(y_test, y_pred)\r\n",
    "# # Assigning columns names\r\n",
    "# cm_df = pd.DataFrame(cm, \r\n",
    "#             columns = ['Predicted COVID+ve', 'Predicted Healthy'],\r\n",
    "#             index = ['Actual COVID+ve', 'Actual Healthy'])\r\n",
    "# # Showing the confusion matrix\r\n",
    "# cm_df\r\n",
    "\r\n",
    "# # Making the Confusion Matrix\r\n",
    "# from sklearn.metrics import confusion_matrix\r\n",
    "# from sklearn.metrics import classification_report\r\n",
    "# clf_rpt = classification_report(y_test,y_pred)\r\n",
    "# print(\"Accuracy =\", accuracy_score(y_test, y_pred))\r\n",
    "# print(clf_rpt)\r\n",
    "# cm = confusion_matrix(y_test, y_pred)\r\n",
    "# sns.heatmap(cm,annot=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "# import eli5\r\n",
    "# # create our dataframe of feature importances\r\n",
    "# feat_imp_df = eli5.explain_weights_df(rfc, feature_names=features)\r\n",
    "# feat_imp_df"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "# Code for converting new audio to required format\r\n",
    "\r\n",
    "path = r'C:\\Users\\DELL\\COV_Project\\Files\\cough-heavy.wav'\r\n",
    "def preproces(fn_wav):\r\n",
    "    y, sr = librosa.load(fn_wav, mono=True, duration=5)\r\n",
    "    chroma_stft = librosa.feature.chroma_stft(y=y, sr=sr)\r\n",
    "    rmse = librosa.feature.rms(y=y)\r\n",
    "    spectral_centroid = librosa.feature.spectral_centroid(y=y, sr=sr)\r\n",
    "    spectral_bandwidth = librosa.feature.spectral_bandwidth(y=y, sr=sr)\r\n",
    "    rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr)\r\n",
    "    zcr = librosa.feature.zero_crossing_rate(y)\r\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=sr)\r\n",
    "    \r\n",
    "    feature_row = {        \r\n",
    "        'chroma_stft': np.mean(chroma_stft),\r\n",
    "        'rmse': np.mean(rmse),\r\n",
    "        'spectral_centroid': np.mean(spectral_centroid),\r\n",
    "        'spectral_bandwidth': np.mean(spectral_bandwidth),\r\n",
    "        'rolloff': np.mean(rolloff),\r\n",
    "        'zero_crossing_rate': np.mean(zcr),        \r\n",
    "    }\r\n",
    "    for i, c in enumerate(mfcc):\r\n",
    "        feature_row[f'mfcc{i+1}'] = np.mean(c)\r\n",
    "    \r\n",
    "    return feature_row\r\n",
    "\r\n",
    "def get_dataframe(feature_row):\r\n",
    "    data = pd.DataFrame.from_dict(feature_row, orient='index')\r\n",
    "    data2 = data.T\r\n",
    "    return data2\r\n",
    "\r\n",
    "feature = preproces(path)\r\n",
    "# data = pd.DataFrame.from_dict(feature, orient='index')\r\n",
    "# data2 = data.T\r\n",
    "\r\n",
    "def scaler_transform(feature):\r\n",
    "    df = pd.read_csv(r\"C:\\Users\\DELL\\COV_Project\\Files\\smote_no_encode.csv\") #Source File\r\n",
    "    scaler = MinMaxScaler()\r\n",
    "    X = scaler.fit_transform(np.array(df.iloc[:, :-1]))\r\n",
    "    X_s = pd.DataFrame(X, columns = features)\r\n",
    "    X_s['label'] = df['label']\r\n",
    "    test_normalised = scaler.transform(feature)\r\n",
    "    return test_normalised\r\n",
    "\r\n",
    "def to_scaled_feature(path):\r\n",
    "    retro = preproces(path)\r\n",
    "    retro1 = get_dataframe(retro)\r\n",
    "    test_data = scaler_transform(retro1)\r\n",
    "    return test_data   "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "def smote_preprocess(old_file, new_file):\r\n",
    "    df_old = pd.read_csv(old_file)\r\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=2, test_size=0.30)\r\n",
    "    # build model with SMOTE imblearn\r\n",
    "    smote_pipeline = make_pipeline_imb(SMOTE(random_state=4), \\\r\n",
    "                                   classifier(random_state=42))\r\n",
    "    smote_model = smote_pipeline.fit(X_train, y_train)\r\n",
    "    #Showing the diference before and after the transformation used\r\n",
    "    print(\"normal data distribution: {}\".format(Counter(y)))\r\n",
    "    X_smote, y_smote = SMOTE().fit_sample(X, y)\r\n",
    "    print(\"SMOTE data distribution: {}\".format(Counter(y_smote)))\r\n",
    "    X_s = pd.DataFrame(X_smote, columns = features)\r\n",
    "    y_s = pd.DataFrame(y_smote, columns = ['label'])\r\n",
    "    X_s['label'] = y_s\r\n",
    "    X_s.to_csv(new_file, index=False)\r\n",
    "    return new_file"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "pip install ffmpeg"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting ffmpeg\n",
      "  Downloading ffmpeg-1.4.tar.gz (5.1 kB)\n",
      "Building wheels for collected packages: ffmpeg\n",
      "  Building wheel for ffmpeg (setup.py): started\n",
      "  Building wheel for ffmpeg (setup.py): finished with status 'done'\n",
      "  Created wheel for ffmpeg: filename=ffmpeg-1.4-py3-none-any.whl size=6083 sha256=82113cfd5f10e0c390951ee8a54071a7b1e5c12d6ad41cd42fd3babb6873b514\n",
      "  Stored in directory: c:\\users\\dell\\appdata\\local\\pip\\cache\\wheels\\30\\33\\46\\5ab7eca55b9490dddbf3441c68a29535996270ef1ce8b9b6d7\n",
      "Successfully built ffmpeg\n",
      "Installing collected packages: ffmpeg\n",
      "Successfully installed ffmpeg-1.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING: Ignoring invalid distribution -mpy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -treamlit (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -mpy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -lick (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -arkupsafe (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -mpy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -treamlit (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -mpy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -lick (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -arkupsafe (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -mpy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -treamlit (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -mpy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -lick (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -arkupsafe (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -mpy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -treamlit (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -mpy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -lick (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -arkupsafe (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -mpy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -treamlit (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -mpy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -lick (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -arkupsafe (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -mpy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -treamlit (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -mpy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -lick (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -arkupsafe (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -mpy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -treamlit (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -mpy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -lick (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -arkupsafe (c:\\programdata\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "import os,sys\r\n",
    "from pydub import AudioSegment"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "orig_song = r\"C:\\Users\\DELL\\COV_Project\\Files\\virufy-cdf-coughvid_0007c6f1-5441-40e6-9aaf-a761d8f2da3b.webm\" # Name of the person.ogg\r\n",
    "dest_song = 'file_example_OOG_5MG.wav'#orig_song\r\n",
    "#dest_song1 = orig_song.split(\", \")[0]\r\n",
    "\r\n",
    "def convert_webm_to_wav():\r\n",
    "    song = AudioSegment.from_ogg(orig_song)\r\n",
    "    song.export(dest_song, format=\"wav\")\r\n",
    "    \r\n",
    "if __name__ == '__main__':\r\n",
    "    convert_webm_to_wav()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pydub\\utils.py:198: RuntimeWarning: Couldn't find ffprobe or avprobe - defaulting to ffprobe, but may not work\n",
      "  warn(\"Couldn't find ffprobe or avprobe - defaulting to ffprobe, but may not work\", RuntimeWarning)\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "FileNotFoundError",
     "evalue": "[WinError 2] The system cannot find the file specified",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-90f48c4ca563>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'__main__'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mconvert_webm_to_wav\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-5-90f48c4ca563>\u001b[0m in \u001b[0;36mconvert_webm_to_wav\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mconvert_webm_to_wav\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0msong\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAudioSegment\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_ogg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morig_song\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0msong\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexport\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdest_song\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"wav\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pydub\\audio_segment.py\u001b[0m in \u001b[0;36mfrom_ogg\u001b[1;34m(cls, file, parameters)\u001b[0m\n\u001b[0;32m    802\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    803\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfrom_ogg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 804\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'ogg'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    805\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    806\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pydub\\audio_segment.py\u001b[0m in \u001b[0;36mfrom_file\u001b[1;34m(cls, file, format, codec, parameters, start_second, duration, **kwargs)\u001b[0m\n\u001b[0;32m    726\u001b[0m             \u001b[0minfo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    727\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 728\u001b[1;33m             \u001b[0minfo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmediainfo_json\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morig_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mread_ahead_limit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mread_ahead_limit\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    729\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minfo\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    730\u001b[0m             audio_streams = [x for x in info['streams']\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pydub\\utils.py\u001b[0m in \u001b[0;36mmediainfo_json\u001b[1;34m(filepath, read_ahead_limit)\u001b[0m\n\u001b[0;32m    272\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    273\u001b[0m     \u001b[0mcommand\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mprober\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'-of'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'json'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mcommand_args\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 274\u001b[1;33m     \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstdin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstdin_parameter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstdout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mPIPE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstderr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mPIPE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    275\u001b[0m     \u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstderr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommunicate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstdin_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    276\u001b[0m     \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"utf-8\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'ignore'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\subprocess.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, encoding, errors, text)\u001b[0m\n\u001b[0;32m    856\u001b[0m                             encoding=encoding, errors=errors)\n\u001b[0;32m    857\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 858\u001b[1;33m             self._execute_child(args, executable, preexec_fn, close_fds,\n\u001b[0m\u001b[0;32m    859\u001b[0m                                 \u001b[0mpass_fds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcwd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    860\u001b[0m                                 \u001b[0mstartupinfo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreationflags\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshell\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\subprocess.py\u001b[0m in \u001b[0;36m_execute_child\u001b[1;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, unused_restore_signals, unused_start_new_session)\u001b[0m\n\u001b[0;32m   1309\u001b[0m             \u001b[1;31m# Start the process\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1310\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1311\u001b[1;33m                 hp, ht, pid, tid = _winapi.CreateProcess(executable, args,\n\u001b[0m\u001b[0;32m   1312\u001b[0m                                          \u001b[1;31m# no special security\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1313\u001b[0m                                          \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] The system cannot find the file specified"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "ffmpeg -i orig_song -crf 23 \"out.wav\""
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-7-b936fa9a6aa2>, line 1)",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-7-b936fa9a6aa2>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    ffmpeg -i r\"Files\\virufy-cdf-coughvid_0007c6f1-5441-40e6-9aaf-a761d8f2da3b.webm\" -crf 23 \"out.wav\"\u001b[0m\n\u001b[1;37m              ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 13470.126256,
   "end_time": "2021-06-24T10:10:43.907785",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-06-24T06:26:13.781529",
   "version": "2.3.3"
  },
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}