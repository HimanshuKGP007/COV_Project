{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Loading Libraries","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.applications import MobileNetV2\nfrom tensorflow.keras.layers import Dense, Conv2D, MaxPool2D, Flatten, Dropout\nimport time\n\nimport matplotlib.pyplot as plt\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-10-21T18:17:45.189725Z","iopub.execute_input":"2021-10-21T18:17:45.190042Z","iopub.status.idle":"2021-10-21T18:17:45.197229Z","shell.execute_reply.started":"2021-10-21T18:17:45.190013Z","shell.execute_reply":"2021-10-21T18:17:45.196145Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"# Data Augmentation","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\ndata_generator = ImageDataGenerator(rescale=1./255.,validation_split=0.2,\n                                   featurewise_center=True,\n        samplewise_center=True,\n        featurewise_std_normalization=True,\n        samplewise_std_normalization=True,\n        rotation_range=20,\n        width_shift_range=0.2,\n        height_shift_range=0.2,\n        shear_range=0.15,\n        zoom_range=0.15,\n        fill_mode=\"nearest\",\n        horizontal_flip=True,\n        vertical_flip=True\n                        )\ntrain_generator = data_generator.flow_from_directory(directory= '../input/cough-detection/melspectrograms/training',             \n                                                     target_size=(224, 224),\n                                                     class_mode='binary',\n                                                     subset='training',\n                                                     shuffle=True,\n                                                     seed=2,\n                                                     batch_size=32,\n                                                     color_mode='rgb'\n                                                     )\n\nvalid_generator = data_generator.flow_from_directory(directory= '../input/cough-detection/melspectrograms/testing',\n                                                     target_size=(224, 224),\n                                                     class_mode='binary',\n                                                     subset='validation',\n                                                     shuffle=True,\n                                                     batch_size=32,\n                                                     color_mode='rgb'\n                                                    )\n\nclasses = ['cough', 'no_cough']","metadata":{"execution":{"iopub.status.busy":"2021-10-21T18:17:45.206891Z","iopub.execute_input":"2021-10-21T18:17:45.207195Z","iopub.status.idle":"2021-10-21T18:17:46.090804Z","shell.execute_reply.started":"2021-10-21T18:17:45.207168Z","shell.execute_reply":"2021-10-21T18:17:46.089250Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"# Data Visualization","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(10,10))\nplt.subplot(2,2,1)\nplt.bar(classes, train_generator.labels.sum(axis = 0)/train_generator.n * 100)\nplt.title('On training set')\nplt.subplot(2,2,2)\nplt.bar(classes, valid_generator.labels.sum(axis = 0)/valid_generator.n * 100, color='rgb')\nplt.title('On validation set')","metadata":{"execution":{"iopub.status.busy":"2021-10-21T18:17:46.092733Z","iopub.execute_input":"2021-10-21T18:17:46.093079Z","iopub.status.idle":"2021-10-21T18:17:46.416673Z","shell.execute_reply.started":"2021-10-21T18:17:46.093042Z","shell.execute_reply":"2021-10-21T18:17:46.415683Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"sample_training_images, _ = next(train_generator)","metadata":{"execution":{"iopub.status.busy":"2021-10-21T18:17:46.418189Z","iopub.execute_input":"2021-10-21T18:17:46.418743Z","iopub.status.idle":"2021-10-21T18:17:47.138756Z","shell.execute_reply.started":"2021-10-21T18:17:46.418698Z","shell.execute_reply":"2021-10-21T18:17:47.138014Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"def plotImages(images_arr):\n    fig, axes = plt.subplots(1, 5, figsize=(20,20))\n    labels = sample_training_images\n    axes = axes.flatten()\n    for img, ax in zip(images_arr, axes):\n        ax.imshow(img)\n        ax.axis('off')\n    plt.tight_layout()\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-21T18:17:47.140153Z","iopub.execute_input":"2021-10-21T18:17:47.140471Z","iopub.status.idle":"2021-10-21T18:17:47.146931Z","shell.execute_reply.started":"2021-10-21T18:17:47.140436Z","shell.execute_reply":"2021-10-21T18:17:47.146095Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"plotImages(sample_training_images[:5])","metadata":{"execution":{"iopub.status.busy":"2021-10-21T18:17:47.150599Z","iopub.execute_input":"2021-10-21T18:17:47.151202Z","iopub.status.idle":"2021-10-21T18:17:47.493382Z","shell.execute_reply.started":"2021-10-21T18:17:47.151161Z","shell.execute_reply":"2021-10-21T18:17:47.489931Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"model = tf.keras.models.Sequential()\nmodel.add(MobileNetV2(include_top=False, pooling='avg', weights='imagenet', input_shape=(224, 224, 3), classes=2))\nmodel.add(Dense(2, activation='softmax'))\nmodel.layers[0].trainable = False\nmodel.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2021-10-21T18:17:47.496324Z","iopub.execute_input":"2021-10-21T18:17:47.496678Z","iopub.status.idle":"2021-10-21T18:17:53.805443Z","shell.execute_reply.started":"2021-10-21T18:17:47.496639Z","shell.execute_reply":"2021-10-21T18:17:53.804598Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"callbacks = tf.keras.callbacks.EarlyStopping(monitor = 'val_accuracy', patience = 2)\nhistory = model.fit_generator(train_generator,\n                              steps_per_epoch = len(train_generator),\n                              epochs=10,\n                              validation_steps = len(valid_generator),\n                              validation_data=valid_generator,\n                              callbacks = [callbacks]\n                              )","metadata":{"execution":{"iopub.status.busy":"2021-10-21T18:17:53.806788Z","iopub.execute_input":"2021-10-21T18:17:53.807113Z","iopub.status.idle":"2021-10-21T18:19:08.368560Z","shell.execute_reply.started":"2021-10-21T18:17:53.807080Z","shell.execute_reply":"2021-10-21T18:19:08.367648Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"def visualize_training(history, lw = 3):\n    plt.figure(figsize=(10,6))\n    plt.plot(history.history['accuracy'], label = 'training', marker = '*', linewidth = lw)\n    plt.plot(history.history['val_accuracy'], label = 'validation', marker = 'o', linewidth = lw)\n    plt.title('Training Accuracy vs Validation Accuracy')\n    plt.xlabel('Epochs')\n    plt.ylabel('Accuracy')\n    plt.legend(fontsize = 'x-large')\n    plt.show()\n\n    plt.figure(figsize=(10,6))\n    plt.plot(history.history['loss'], label = 'training', marker = '*', linewidth = lw)\n    plt.plot(history.history['val_loss'], label = 'validation', marker = 'o', linewidth = lw)\n    plt.title('Training Loss vs Validation Loss')\n    plt.xlabel('Epochs')\n    plt.ylabel('Loss')\n    plt.legend(fontsize = 'x-large')\n    plt.show()\nvisualize_training(history)","metadata":{"execution":{"iopub.status.busy":"2021-10-21T18:19:08.370261Z","iopub.execute_input":"2021-10-21T18:19:08.370660Z","iopub.status.idle":"2021-10-21T18:19:08.710085Z","shell.execute_reply.started":"2021-10-21T18:19:08.370621Z","shell.execute_reply":"2021-10-21T18:19:08.709179Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"# Predictions","metadata":{}},{"cell_type":"code","source":"preds = model.predict_generator(valid_generator,steps=15)","metadata":{"execution":{"iopub.status.busy":"2021-10-21T18:19:08.711951Z","iopub.execute_input":"2021-10-21T18:19:08.712530Z","iopub.status.idle":"2021-10-21T18:19:11.148060Z","shell.execute_reply.started":"2021-10-21T18:19:08.712484Z","shell.execute_reply":"2021-10-21T18:19:11.147145Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"label = valid_generator.classes","metadata":{"execution":{"iopub.status.busy":"2021-10-21T18:19:11.149632Z","iopub.execute_input":"2021-10-21T18:19:11.149958Z","iopub.status.idle":"2021-10-21T18:19:11.154463Z","shell.execute_reply.started":"2021-10-21T18:19:11.149922Z","shell.execute_reply":"2021-10-21T18:19:11.153433Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"pred= model.predict(valid_generator)\npredicted_class_indices=np.argmax(pred,axis=1)\nlabels = (valid_generator.class_indices)\nlabels2 = dict((v,k) for k,v in labels.items())\npredictions = [labels2[k] for k in predicted_class_indices]\nprint(predicted_class_indices)\nprint (labels)\nprint (predictions)","metadata":{"execution":{"iopub.status.busy":"2021-10-21T18:19:11.156443Z","iopub.execute_input":"2021-10-21T18:19:11.157181Z","iopub.status.idle":"2021-10-21T18:19:12.810637Z","shell.execute_reply.started":"2021-10-21T18:19:11.157106Z","shell.execute_reply":"2021-10-21T18:19:12.809844Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"image_path = '../input/cough-detection/melspectrograms/testing/cough/1-63679-A-24.png'\nimage = tf.keras.preprocessing.image.load_img(image_path)\ninput_arr = tf.keras.preprocessing.image.img_to_array(image)\ninput_arr = np.array([input_arr])  # Convert single image to a batch.\npredictions = model.predict(input_arr)","metadata":{"execution":{"iopub.status.busy":"2021-10-21T18:19:12.813024Z","iopub.execute_input":"2021-10-21T18:19:12.813566Z","iopub.status.idle":"2021-10-21T18:19:13.647411Z","shell.execute_reply.started":"2021-10-21T18:19:12.813525Z","shell.execute_reply":"2021-10-21T18:19:13.646540Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# #Loading CSV file\n# train_csv = pd.read_csv(\"../input/coughclassifier-trial/cough_trial_extended.csv\")\n# dataset = \"../input/coughclassifier-trial/cough_trial_extended.csv\"\n\n# cmap = plt.get_cmap('inferno')\n# tot_rows = train_csv.shape[0]\n# for i in range(tot_rows):\n#     source = train_csv['file_properties'][i]\n#     filename = '../input/coughclassifier-trial/trial_covid/'+source\n#     y,sr = librosa.load(filename, mono=True, duration=5)\n#     plt.specgram(y, NFFT=2048, Fs=2, Fc=0, noverlap=128, cmap=cmap, sides='default', mode='default', scale='dB');\n#     plt.axis('off');\n#     plt.savefig(f'./{source[:-3].replace(\".\", \"\")}.png')\n#     plt.clf()","metadata":{"execution":{"iopub.status.busy":"2021-10-21T18:19:13.648875Z","iopub.execute_input":"2021-10-21T18:19:13.649225Z","iopub.status.idle":"2021-10-21T18:19:13.654051Z","shell.execute_reply.started":"2021-10-21T18:19:13.649188Z","shell.execute_reply":"2021-10-21T18:19:13.653037Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"import librosa\nimport librosa.display\nfrom pydub import AudioSegment\nimport matplotlib.pyplot as plt\nfrom scipy.io import wavfile\nfrom tempfile import mktemp\n\ndef plot_mp3_matplot(filename):\n    \"\"\"\n    plot_mp3_matplot -- using matplotlib to simply plot time vs amplitude waveplot\n    \n    Arguments:\n    filename -- filepath to the file that you want to see the waveplot for\n    \n    Returns -- None\n    \"\"\"\n    \n    # sr is for 'sampling rate'\n    # Feel free to adjust it\n    x, sr = librosa.load(filename, sr=44100)\n    plt.figure(figsize=(14, 5))\n    librosa.display.waveplot(x, sr=sr)\n\ndef convert_audio_to_spectogram(filename):\n    \"\"\"\n    convert_audio_to_spectogram -- using librosa to simply plot a spectogram\n    \n    Arguments:\n    filename -- filepath to the file that you want to see the waveplot for\n    \n    Returns -- None\n    \"\"\"\n    \n    # sr == sampling rate \n    x, sr = librosa.load(filename, sr=44100)\n    \n    # stft is short time fourier transform\n    X = librosa.stft(x)\n    \n    # convert the slices to amplitude\n    Xdb = librosa.amplitude_to_db(abs(X))\n    \n    # ... and plot, magic!\n    plt.figure(figsize=(14, 5))\n    librosa.display.specshow(Xdb, sr = sr, x_axis = 'time', y_axis = 'hz')\n    plt.colorbar()\n    \n# same as above, just changed the y_axis from hz to log in the display func    \ndef convert_audio_to_spectogram_log(filename):\n    x, sr = librosa.load(filename, sr=44100)\n    X = librosa.stft(x)\n    Xdb = librosa.amplitude_to_db(abs(X))\n    plt.figure(figsize=(14, 5))\n    librosa.display.specshow(Xdb, sr = sr, x_axis = 'time', y_axis = 'log')\n    plt.colorbar()    ","metadata":{"execution":{"iopub.status.busy":"2021-10-21T18:19:13.656158Z","iopub.execute_input":"2021-10-21T18:19:13.656910Z","iopub.status.idle":"2021-10-21T18:19:15.066335Z","shell.execute_reply.started":"2021-10-21T18:19:13.656822Z","shell.execute_reply":"2021-10-21T18:19:15.065442Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"convert_audio_to_spectogram_log('../input/covid-cough-wavs/cleaned_data/Positive/1041_Positive_male_39.wav')","metadata":{"execution":{"iopub.status.busy":"2021-10-21T18:19:15.069855Z","iopub.execute_input":"2021-10-21T18:19:15.070141Z","iopub.status.idle":"2021-10-21T18:19:16.799650Z","shell.execute_reply.started":"2021-10-21T18:19:15.070094Z","shell.execute_reply":"2021-10-21T18:19:16.798606Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Convert new audio recording to MelSpectogram\n%matplotlib inline\nimport librosa\ncmap = plt.get_cmap('inferno')\nsource = '../input/covid-cough-wavs/cleaned_data/Positive/1066_Positive_male_23.wav'\nfilname = '../input/covid-cough-wavs/cleaned_data/Positive'\nfilename = source\ny,sr = librosa.load(filename, mono=True)\nplt.specgram(y, NFFT=2048, Fs=2, Fc=0, noverlap=128, cmap=cmap, sides='default', mode='default', scale='dB');\n#plt.axis('off');\n#plt.savefig(f'source1.png')\nplt.savefig('foo1.png')\nplt.clf()","metadata":{"execution":{"iopub.status.busy":"2021-10-21T18:19:16.804502Z","iopub.execute_input":"2021-10-21T18:19:16.806345Z","iopub.status.idle":"2021-10-21T18:19:17.292401Z","shell.execute_reply.started":"2021-10-21T18:19:16.806253Z","shell.execute_reply":"2021-10-21T18:19:17.291497Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions","metadata":{"execution":{"iopub.status.busy":"2021-10-21T18:19:17.293700Z","iopub.execute_input":"2021-10-21T18:19:17.294216Z","iopub.status.idle":"2021-10-21T18:19:17.302223Z","shell.execute_reply.started":"2021-10-21T18:19:17.294175Z","shell.execute_reply":"2021-10-21T18:19:17.300961Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"image_path = 'foo1.png'\nimage = tf.keras.preprocessing.image.load_img(image_path)\ninput_arr = tf.keras.preprocessing.image.img_to_array(image)\ninput_arr = np.array([input_arr])  # Convert single image to a batch.\npredictions1 = model.predict(input_arr)","metadata":{"execution":{"iopub.status.busy":"2021-10-21T18:19:17.303597Z","iopub.execute_input":"2021-10-21T18:19:17.304235Z","iopub.status.idle":"2021-10-21T18:19:17.350862Z","shell.execute_reply.started":"2021-10-21T18:19:17.304191Z","shell.execute_reply":"2021-10-21T18:19:17.350140Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"predictions1","metadata":{"execution":{"iopub.status.busy":"2021-10-21T18:19:17.352188Z","iopub.execute_input":"2021-10-21T18:19:17.352516Z","iopub.status.idle":"2021-10-21T18:19:17.357760Z","shell.execute_reply.started":"2021-10-21T18:19:17.352477Z","shell.execute_reply":"2021-10-21T18:19:17.356699Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"# Predicting Non Cough samples","metadata":{}},{"cell_type":"code","source":"image_path = '../input/cough-detection/melspectrograms/testing/cough/1-63679-A-24.png'\nimage = tf.keras.preprocessing.image.load_img(image_path)\ninput_arr = tf.keras.preprocessing.image.img_to_array(image)\ninput_arr = np.array([input_arr])  # Convert single image to a batch.\npredictions_nocough = model.predict(input_arr)","metadata":{"execution":{"iopub.status.busy":"2021-10-21T18:22:58.896587Z","iopub.execute_input":"2021-10-21T18:22:58.896935Z","iopub.status.idle":"2021-10-21T18:22:58.941318Z","shell.execute_reply.started":"2021-10-21T18:22:58.896906Z","shell.execute_reply":"2021-10-21T18:22:58.940531Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"predictions_nocough","metadata":{"execution":{"iopub.status.busy":"2021-10-21T18:22:59.879603Z","iopub.execute_input":"2021-10-21T18:22:59.879935Z","iopub.status.idle":"2021-10-21T18:22:59.887641Z","shell.execute_reply.started":"2021-10-21T18:22:59.879907Z","shell.execute_reply":"2021-10-21T18:22:59.886238Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix, classification_report, roc_curve\n\nrc = roc_curve(predicted_class_indices,label)\ncf_matrix = confusion_matrix(predicted_class_indices,label)\ncf_report = classification_report(predicted_class_indices,label)\nprint('Confusion matrix report of the model : \\n{}'.format(cf_matrix))","metadata":{"execution":{"iopub.status.busy":"2021-10-21T18:19:17.425711Z","iopub.execute_input":"2021-10-21T18:19:17.426004Z","iopub.status.idle":"2021-10-21T18:19:17.446901Z","shell.execute_reply.started":"2021-10-21T18:19:17.425974Z","shell.execute_reply":"2021-10-21T18:19:17.445889Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"exp_series = pd.Series(label)\npred_series = pd.Series(predicted_class_indices)\npd.crosstab(exp_series, pred_series, rownames=['Actual'], colnames=['Predicted'],margins=True)","metadata":{"execution":{"iopub.status.busy":"2021-10-21T18:19:17.448072Z","iopub.execute_input":"2021-10-21T18:19:17.448438Z","iopub.status.idle":"2021-10-21T18:19:17.515606Z","shell.execute_reply.started":"2021-10-21T18:19:17.448401Z","shell.execute_reply":"2021-10-21T18:19:17.514708Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"print('Classification report of the model : \\n{}'.format(cf_report))","metadata":{"execution":{"iopub.status.busy":"2021-10-21T18:19:17.517124Z","iopub.execute_input":"2021-10-21T18:19:17.517682Z","iopub.status.idle":"2021-10-21T18:19:17.523695Z","shell.execute_reply.started":"2021-10-21T18:19:17.517642Z","shell.execute_reply":"2021-10-21T18:19:17.522379Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"markdown","source":"# Saving Model","metadata":{}},{"cell_type":"code","source":"t = time.time()\nsave_path = '.'\nmodel_json = model.to_json()\nwith open(os.path.join(save_path,\"network.json\"), \"w\") as json_file:\n    json_file.write(model_json)\n\n# save neural network structure to YAML (no weights)\nmodel_yaml = model.to_yaml()\nwith open(os.path.join(save_path,\"network.yaml\"), \"w\") as yaml_file:\n    yaml_file.write(model_yaml)\n\n# save entire network to HDF5 (save everything, suggested)\nmodel.save(os.path.join(save_path,\"network.h5\"))","metadata":{"execution":{"iopub.status.busy":"2021-10-21T18:19:17.525476Z","iopub.execute_input":"2021-10-21T18:19:17.526187Z","iopub.status.idle":"2021-10-21T18:19:18.195439Z","shell.execute_reply.started":"2021-10-21T18:19:17.526143Z","shell.execute_reply":"2021-10-21T18:19:18.194614Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"!ls","metadata":{"execution":{"iopub.status.busy":"2021-10-21T18:19:18.198817Z","iopub.execute_input":"2021-10-21T18:19:18.199079Z","iopub.status.idle":"2021-10-21T18:19:18.906327Z","shell.execute_reply.started":"2021-10-21T18:19:18.199053Z","shell.execute_reply":"2021-10-21T18:19:18.905145Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"markdown","source":"# Loading the Saved Model and Predictions","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.models import load_model\nmodel2 = load_model(os.path.join(save_path,\"network.h5\"))\npred = model2.predict(input_arr)\npred","metadata":{"execution":{"iopub.status.busy":"2021-10-21T18:19:18.908466Z","iopub.execute_input":"2021-10-21T18:19:18.908919Z","iopub.status.idle":"2021-10-21T18:19:23.827458Z","shell.execute_reply.started":"2021-10-21T18:19:18.908872Z","shell.execute_reply":"2021-10-21T18:19:23.822218Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}